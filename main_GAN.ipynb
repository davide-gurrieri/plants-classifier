{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Colab\n","Run the following part only if you opened this notebook in Google Colab."]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/davide-gurrieri/plants-classifier/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'plants-classifier'...\n","remote: Enumerating objects: 52, done.\u001b[K\n","remote: Counting objects: 100% (52/52), done.\u001b[K\n","remote: Compressing objects: 100% (37/37), done.\u001b[K\n","^Cceiving objects:  51% (27/52), 932.00 KiB | 217.00 KiB/s\n","[Errno 2] No such file or directory: 'plants-classifier/'\n","/home/gurro/ARTIFICIAL/plants-classifier\n","/home/gurro/ARTIFICIAL\n"]}],"source":["## THIS CELL IS USED CLONE YOUR PRIVATE REPOSITORY IN COLAB\n","## to generate fine-grained token: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n","TOKEN = \"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\"\n","REPO_URL= \"github.com/davide-gurrieri/plants-classifier.git\"\n","USER_NAME = \"davide-gurrieri\"\n","USER_EMAIL = \"gurrieri99@gmail.com\"\n","\n","!git clone --branch main https://oauth2:$TOKEN@$REPO_URL\n","%cd plants-classifier/\n","!git remote set-url origin  https://oauth2:$TOKEN@$REPO_URL\n","!git config user.name $USER_NAME\n","!git config user.email $USER_EMAIL\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import the data from the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Copy the data from the drive to the local repository folder\n","%cp \"drive/MyDrive/[2023-2024] AN2DL/Homework 1/public_data.zip\" \"plants-classifier/data/\"\n","# Unzip the data\n","!unzip plants-classifier/data/public_data.zip -d plants-classifier/data/\n","# Remove the zip file\n","!rm plants-classifier/data/public_data.zip\n","%cd plants-classifier/"]},{"cell_type":"markdown","metadata":{},"source":["Now you are ready to run the notebook. You are inside the folder `plants-classifier`."]},{"cell_type":"markdown","metadata":{"id":"MdD_8Vyswkwf"},"source":["## Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-12 17:17:51.815821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-12 17:17:51.815868: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-12 17:17:51.815893: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-12 17:17:51.827155: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["2.14.0\n"]}],"source":["import visualkeras\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import shutil\n","import random\n","import glob\n","import imageio\n","from PIL import Image\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","import logging\n","import pandas as pd\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def data_processing(name=\"data/public_data.npz\"):\n","    # Load data\n","    dataset = np.load(\"data/public_data.npz\", allow_pickle=True)\n","    X_train_val = dataset[\"data\"]\n","    y_train_val = dataset[\"labels\"]\n","    labels = {0: \"healthy\", 1: \"unhealthy\"}\n","\n","    # convert elements of y_train_val to 0 and 1\n","    y_train_val = np.array([0 if label == \"healthy\" else 1 for label in y_train_val])\n","\n","    # Expand also the labels dimension moving from (x,) to (x, 1), with x cardinality\n","    y_train_val = np.expand_dims(y_train_val, axis=-1)\n","\n","    # remove all the items equal to shrek or trol from the dataset\n","    shrek = X_train_val[58]\n","    trol = X_train_val[338]\n","    index_to_remove = []\n","    for i, imm in enumerate(X_train_val):\n","        if np.allclose(imm, shrek, atol=0.1) or np.allclose(imm, trol, atol=0.1):\n","            index_to_remove.append(i)\n","    X_outliers = X_train_val[index_to_remove]\n","    y_outliers = y_train_val[index_to_remove]\n","    X_train_val_no_out = np.delete(X_train_val, index_to_remove, axis=0)\n","    y_train_val_no_out = np.delete(y_train_val, index_to_remove, axis=0)\n","\n","    # Print dataset information\n","    counting_no_out = pd.DataFrame(y_train_val_no_out, columns=[\"status\"])[\n","        \"status\"\n","    ].value_counts()\n","    counting = pd.DataFrame(y_train_val, columns=[\"status\"])[\"status\"].value_counts()\n","    dataset_info = f\"The dataset without outliers contains {len(X_train_val_no_out)} images of plants, {counting_no_out[0]} healthy and {counting_no_out[1]} unhealthy.\"\n","    dataset_info += f\"\\nThe ratio of the healthy plants over the total is {counting_no_out[0]/len(X_train_val_no_out):.2f}.\"\n","    dataset_info += f\"\\nThe ratio of the healthy plants over the total considering also outliers is {counting[0]/len(X_train_val):.2f}.\"\n","    dataset_info += f\"\\nEach image has shape {X_train_val_no_out[0].shape}.\"\n","    dataset_info += f\"\\nThe labels encoding is: {labels}.\"\n","    print(dataset_info)\n","\n","    return (\n","        X_train_val,\n","        y_train_val,\n","        X_train_val_no_out,\n","        y_train_val_no_out,\n","        labels,\n","        X_outliers,\n","        y_outliers,\n","        shrek,\n","        trol,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"NcLWIZfBUd80"},"source":["## Load, inspect and process data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The dataset without outliers contains 5004 images of plants, 3101 healthy and 1903 unhealthy.\n","The ratio of the healthy plants over the total is 0.62.\n","The ratio of the healthy plants over the total considering also outliers is 0.62.\n","Each image has shape (96, 96, 3).\n","The labels encoding is: {0: 'healthy', 1: 'unhealthy'}.\n","\n","Shape of X_train_val:  (5004, 96, 96, 3)\n","Shape of y_train_val:  (5004, 1)\n"]}],"source":["X_train_val_with_out, y_train_val_with_out, X_train_val, y_train_val, labels, X_out, y_out, shrek, trol = data_processing()\n","print()\n","print(\"Shape of X_train_val: \", X_train_val.shape)\n","print(\"Shape of y_train_val: \", y_train_val.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# np.squeeze(y_train_val).shape"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# data normalization\n","X_train_val = (X_train_val-127.5)/127.5 # Normalize the images to [-1, 1]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(5004, 96, 96, 3)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X_train_val.shape"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["input_shape = X_train_val.shape[1:]\n","input_shape\n","latent_dim = 128"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["X = X_train_val\n","y = np.squeeze(y_train_val)"]},{"cell_type":"markdown","metadata":{},"source":["## Deep Convolutional Conditional GAN"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["image_size = input_shape[0]\n","num_classes = len(np.unique(y))\n","num_channels = input_shape[-1]\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["130 5\n"]}],"source":["generator_in_channels = latent_dim + num_classes\n","discriminator_in_channels = num_channels + num_classes\n","print(generator_in_channels, discriminator_in_channels)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["((96, 96, 5), 130)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["conditional_generator_input = (generator_in_channels)\n","conditional_discriminator_input = (image_size, image_size, discriminator_in_channels)\n","conditional_discriminator_input, conditional_generator_input"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def get_dc_discriminator(input_shape, seed=seed):\n","    tf.random.set_seed(seed)\n","\n","    # Build the discriminator layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","    x = tfkl.ZeroPadding2D((2,2), name='padding')(input_layer)\n","\n","    x = tfkl.Conv2D(64, 3, padding='same', strides=2, name='conv1')(x)\n","    x = tfkl.BatchNormalization(name='bn1')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n","\n","    x = tfkl.Conv2D(128, 3, padding='same', strides=2, name='conv2')(x)\n","    x = tfkl.BatchNormalization(name='bn2')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n","\n","    x = tfkl.Conv2D(256, 3, padding='same', strides=2, name='conv3')(x)\n","    x = tfkl.BatchNormalization(name='bn3')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n","\n","    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n","    x = tfkl.Dropout(.5, seed=seed, name='dropout')(x)\n","    x = tfkl.Dense(1, name='dense_out')(x)\n","    output_layer = tfkl.Activation('sigmoid', name='output_layer')(x)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='discriminator')\n","\n","    # Return the discriminator\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-12 17:18:06.475202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:06.487703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:06.487747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:06.491409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:06.491465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:06.491484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:07.487833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:07.487905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:07.487930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-11-12 17:18:07.487984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-11-12 17:18:07.488026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2070 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]}],"source":["discriminator = get_dc_discriminator(conditional_discriminator_input)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 96, 96, 5)]       0         \n","                                                                 \n"," padding (ZeroPadding2D)     (None, 100, 100, 5)       0         \n","                                                                 \n"," conv1 (Conv2D)              (None, 50, 50, 64)        2944      \n","                                                                 \n"," bn1 (BatchNormalization)    (None, 50, 50, 64)        256       \n","                                                                 \n"," activation1 (LeakyReLU)     (None, 50, 50, 64)        0         \n","                                                                 \n"," conv2 (Conv2D)              (None, 25, 25, 128)       73856     \n","                                                                 \n"," bn2 (BatchNormalization)    (None, 25, 25, 128)       512       \n","                                                                 \n"," activation2 (LeakyReLU)     (None, 25, 25, 128)       0         \n","                                                                 \n"," conv3 (Conv2D)              (None, 13, 13, 256)       295168    \n","                                                                 \n"," bn3 (BatchNormalization)    (None, 13, 13, 256)       1024      \n","                                                                 \n"," activation3 (LeakyReLU)     (None, 13, 13, 256)       0         \n","                                                                 \n"," gap (GlobalAveragePooling2  (None, 256)               0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_out (Dense)           (None, 1)                 257       \n","                                                                 \n"," output_layer (Activation)   (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 374017 (1.43 MB)\n","Trainable params: 373121 (1.42 MB)\n","Non-trainable params: 896 (3.50 KB)\n","_________________________________________________________________\n"]}],"source":["discriminator.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def get_dc_generator(input_shape, seed=seed):\n","    tf.random.set_seed(seed)\n","\n","    # Build the generator layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    x = tfkl.Dense(4*4*64, use_bias=False, name='dense0')(input_layer)\n","    x = tfkl.BatchNormalization(name='bn0')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation0')(x)\n","    x = tfkl.Reshape((4,4,64))(x)\n","\n","    x = tfkl.UpSampling2D(name='upsampling1')(x)\n","    x = tfkl.Conv2D(64, 3, padding='same', use_bias=False, name='conv1')(x)\n","    x = tfkl.BatchNormalization(name='bn1')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n","\n","    x = tfkl.UpSampling2D(name='upsampling2')(x)\n","    x = tfkl.Conv2D(128, 3, padding='same', use_bias=False, name='conv2')(x)\n","    x = tfkl.BatchNormalization(name='bn2')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n","\n","    x = tfkl.UpSampling2D(name='upsampling3')(x)\n","    x = tfkl.Conv2D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n","    x = tfkl.BatchNormalization(name='bn3')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n","    \n","    x = tfkl.UpSampling2D(name='upsampling4')(x)\n","    x = tfkl.Conv2D(512, 3, padding='same', use_bias=False, name='conv4')(x)\n","    x = tfkl.BatchNormalization(name='bn4')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation4')(x)\n","    \n","    x = tfkl.UpSampling2D(name='upsampling5')(x)\n","    x = tfkl.Conv2D(1024, 3, padding='same', use_bias=False, name='conv5')(x)\n","    x = tfkl.BatchNormalization(name='bn5')(x)\n","    x = tfkl.LeakyReLU(alpha=0.2, name='activation5')(x)\n","\n","    x = tfkl.Conv2D(3, 3, padding='same', use_bias=False, name='conv_out')(x)\n","    x = tfkl.Activation('tanh', name='activation_out')(x)\n","    output_layer = tfkl.Cropping2D((16,16), name='cropping')(x)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='generator')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input (InputLayer)          [(None, 130)]             0         \n","                                                                 \n"," dense0 (Dense)              (None, 1024)              133120    \n","                                                                 \n"," bn0 (BatchNormalization)    (None, 1024)              4096      \n","                                                                 \n"," activation0 (LeakyReLU)     (None, 1024)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 4, 4, 64)          0         \n","                                                                 \n"," upsampling1 (UpSampling2D)  (None, 8, 8, 64)          0         \n","                                                                 \n"," conv1 (Conv2D)              (None, 8, 8, 64)          36864     \n","                                                                 \n"," bn1 (BatchNormalization)    (None, 8, 8, 64)          256       \n","                                                                 \n"," activation1 (LeakyReLU)     (None, 8, 8, 64)          0         \n","                                                                 \n"," upsampling2 (UpSampling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2 (Conv2D)              (None, 16, 16, 128)       73728     \n","                                                                 \n"," bn2 (BatchNormalization)    (None, 16, 16, 128)       512       \n","                                                                 \n"," activation2 (LeakyReLU)     (None, 16, 16, 128)       0         \n","                                                                 \n"," upsampling3 (UpSampling2D)  (None, 32, 32, 128)       0         \n","                                                                 \n"," conv3 (Conv2D)              (None, 32, 32, 256)       294912    \n","                                                                 \n"," bn3 (BatchNormalization)    (None, 32, 32, 256)       1024      \n","                                                                 \n"," activation3 (LeakyReLU)     (None, 32, 32, 256)       0         \n","                                                                 \n"," upsampling4 (UpSampling2D)  (None, 64, 64, 256)       0         \n","                                                                 \n"," conv4 (Conv2D)              (None, 64, 64, 512)       1179648   \n","                                                                 \n"," bn4 (BatchNormalization)    (None, 64, 64, 512)       2048      \n","                                                                 \n"," activation4 (LeakyReLU)     (None, 64, 64, 512)       0         \n","                                                                 \n"," upsampling5 (UpSampling2D)  (None, 128, 128, 512)     0         \n","                                                                 \n"," conv5 (Conv2D)              (None, 128, 128, 1024)    4718592   \n","                                                                 \n"," bn5 (BatchNormalization)    (None, 128, 128, 1024)    4096      \n","                                                                 \n"," activation5 (LeakyReLU)     (None, 128, 128, 1024)    0         \n","                                                                 \n"," conv_out (Conv2D)           (None, 128, 128, 3)       27648     \n","                                                                 \n"," activation_out (Activation  (None, 128, 128, 3)       0         \n"," )                                                               \n","                                                                 \n"," cropping (Cropping2D)       (None, 96, 96, 3)         0         \n","                                                                 \n","=================================================================\n","Total params: 6476544 (24.71 MB)\n","Trainable params: 6470528 (24.68 MB)\n","Non-trainable params: 6016 (23.50 KB)\n","_________________________________________________________________\n"]}],"source":["generator = get_dc_generator(conditional_generator_input)\n","generator.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class ConditionalGAN(tfk.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(ConditionalGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","        self.loss_tracker = tfk.metrics.Mean(name=\"loss\")\n","        self.d_loss_tracker = tfk.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_tracker = tfk.metrics.Mean(name=\"g_loss\")\n","\n","    def compile(self, d_optimizer, g_optimizer):\n","        super(ConditionalGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.loss_tracker,\n","            self.d_loss_tracker,\n","            self.g_loss_tracker\n","        ]\n","\n","    @tf.function\n","    def train_step(self, data):\n","        real_images, one_hot_labels = data\n","        batch_size = tf.shape(real_images)[0]\n","        \n","        image_one_hot_labels = one_hot_labels[:, :, None, None]\n","        image_one_hot_labels = tf.repeat(image_one_hot_labels, repeats=[image_size * image_size])\n","        image_one_hot_labels = tf.reshape(image_one_hot_labels, (-1, image_size, image_size, num_classes))\n","        \n","        # Sample random points in the latent space\n","        z = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        z = tf.concat([z, one_hot_labels], -1)\n","\n","        # Generate fake images from z\n","        generated_images = self.generator(z)\n","\n","        \n","        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n","        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n","        # Combine generated images and real ones\n","        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n","\n","        # Create labels so that fake images correspond to class 0 and real images to class 1\n","        labels = tf.concat([tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0)\n","\n","        # Train the discriminator\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = tf.reduce_mean(tfk.losses.binary_crossentropy(labels, predictions))\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(\n","            zip(grads, self.discriminator.trainable_weights)\n","        )\n","\n","        loss = d_loss\n","\n","        # Sample random points in the latent space\n","        z = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        z = tf.concat([z, one_hot_labels], axis=1)\n","\n","        # Create misleading labels for fake images so that they correspond to class 1\n","        misleading_labels = tf.ones((batch_size, 1))\n","\n","        # Train the generator \n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(z)\n","            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n","            misleading_predictions = self.discriminator(fake_image_and_labels)\n","            g_loss = tf.reduce_mean(tfk.losses.binary_crossentropy(misleading_labels, misleading_predictions))\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        loss += g_loss\n","\n","        # Update metrics\n","        self.loss_tracker.update_state(loss)\n","        self.d_loss_tracker.update_state(d_loss)\n","        self.g_loss_tracker.update_state(g_loss)\n","        return {\n","            \"loss\": self.loss_tracker.result(),\n","            \"d_loss\": self.d_loss_tracker.result(),\n","            \"g_loss\": self.g_loss_tracker.result(),\n","        }"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class ConditionalGANMonitor(tfk.callbacks.Callback):\n","    def __init__(self, num_img=10, latent_dim=latent_dim, name='', gray=False):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","        self.name = name\n","        self.gray = gray\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        tf.random.set_seed(seed)\n","        os.makedirs(self.name+'temp', exist_ok=True)\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        labels = tf.cast(tf.math.floormod(tf.range(0,self.num_img), num_classes), 'float32')\n","        labels = tfk.utils.to_categorical(labels, num_classes)\n","        random_latent_vectors = tf.concat([random_latent_vectors,labels],-1)\n","        generated_images = self.model.generator(random_latent_vectors).numpy()\n","\n","        fig, axes = plt.subplots(1, self.num_img, figsize=(20,2*self.num_img))\n","        for i in range(self.num_img):\n","            img = tfk.preprocessing.image.array_to_img(generated_images[i])\n","            ax = axes[i%self.num_img]\n","            if self.gray:\n","                ax.imshow(np.squeeze(img), cmap='gray')\n","            else:\n","                ax.imshow(np.squeeze(img))\n","            ax.axis('off')\n","        fig.savefig(self.name+'temp/'+'{:0>5}'.format(epoch)+'.png') \n","        plt.tight_layout()\n","        plt.show()\n","\n","    def on_train_end(self, logs=None):\n","        fp_in = self.name+\"temp/*.png\"\n","        fp_out = self.name+\"_generated_images.gif\"\n","        imgs = (Image.open(f) for f in sorted(glob.glob(fp_in)))\n","        img = next(imgs)\n","        img.save(fp=fp_out, format='GIF', append_images=imgs, save_all=True, duration=100, optimize=False)    \n","        shutil.rmtree(self.name+\"temp\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 0.],\n","       [1., 0.],\n","       [1., 0.],\n","       ...,\n","       [1., 0.],\n","       [1., 0.],\n","       [1., 0.]], dtype=float32)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["all_labels = tfk.utils.to_categorical(y, num_classes)\n","all_labels"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-12 17:18:21.056666: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 553402368 exceeds 10% of free system memory.\n","2023-11-12 17:18:21.449460: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 553402368 exceeds 10% of free system memory.\n"]}],"source":["dataset = tf.data.Dataset.from_tensor_slices((X, all_labels))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["batch_size = 128\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["cgan = ConditionalGAN(\n","    discriminator = get_dc_discriminator(conditional_discriminator_input), \n","    generator = get_dc_generator(conditional_generator_input), \n","    latent_dim = latent_dim\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["learning_rate = 5e-5\n","cgan.compile(\n","    d_optimizer = tfk.optimizers.Adam(learning_rate=learning_rate),\n","    g_optimizer = tfk.optimizers.Adam(learning_rate=learning_rate)\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def conditional_sample(model, num_img, latent_dim, fixed=True, gray=False, label=None):\n","    if fixed:\n","        tf.random.set_seed(seed)\n","    z = tf.random.normal(shape=(num_img, latent_dim))\n","    if label == None:\n","        labels = tf.cast(tf.math.floormod(tf.range(0,num_img), num_classes), 'float32')\n","    else:\n","        labels = tf.cast(tf.math.floormod(tf.ones(num_img)*label, num_classes), 'float32')\n","    labels = tfk.utils.to_categorical(labels, num_classes)\n","    z = tf.concat([z,labels],-1)\n","    generated_images = model(z).numpy()\n","\n","    fig, axes = plt.subplots(1, num_img, figsize=(20,2*num_img))\n","    for i in range(num_img):\n","        img = tfk.preprocessing.image.array_to_img(generated_images[i])\n","        ax = axes[i%num_img]\n","        if gray:\n","            ax.imshow(np.squeeze(img), cmap='gray')\n","        else:\n","            ax.imshow(np.squeeze(img))\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","    \n","def generate_conditional_dataset(model, num_img, latent_dim, fixed=True, label=None):\n","    if fixed:\n","        tf.random.set_seed(seed)\n","    z = tf.random.normal(shape=(num_img, latent_dim))\n","    if label == None:\n","        labels = tf.cast(tf.math.floormod(tf.range(0,num_img), num_classes), 'float32')\n","    else:\n","        labels = tf.cast(tf.math.floormod(tf.ones(num_img)*label, num_classes), 'float32')\n","    labels = tfk.utils.to_categorical(labels, num_classes)\n","    z = tf.concat([z,labels],-1)\n","    generated_images = model(z).numpy()\n","    return generated_images, labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conditional_sample(cgan.generator, 10, latent_dim, gray=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 100\n","c_history = cgan.fit(\n","    dataset, \n","    epochs = epochs, \n","    callbacks = [ConditionalGANMonitor(name='conditional', gray=False)],\n","    verbose = 2\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the training\n","plt.figure(figsize=(20,5))\n","plt.plot(c_history['loss'], label='GAN loss', alpha=.8, linewidth=3)\n","plt.legend(loc='upper left')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(20,5))\n","plt.plot(c_history['d_loss'], label='Discriminator loss', alpha=.8, linewidth=3)\n","plt.legend(loc='upper left')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(20,5))\n","plt.plot(c_history['g_loss'], label='Generator loss', alpha=.8, linewidth=3)\n","plt.legend(loc='upper left')\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cgan.generator.save('conditional_gan_generator')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conditional_gan_generator = tfk.models.load_model('conditional_gan_generator')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conditional_sample(conditional_gan_generator, 10, latent_dim, fixed=False, gray=False)\n","conditional_sample(conditional_gan_generator, 10, latent_dim, fixed=False, gray=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imgs = 2500\n","X_hat, y_hat = generate_conditional_dataset(conditional_gan_generator, imgs, latent_dim)\n","X_hat = np.reshape(X_hat, (X_hat.shape[0],X_hat.shape[1]*X_hat.shape[2]))*127.5 + 127.5\n","X_hat = np.mean(X_hat, axis=0)\n","y_hat = np.argmax(y_hat,axis=1)\n","\n","X_temp = X[:imgs]*127.5 + 127.5\n","X_temp = np.reshape(X_temp, (X_temp.shape[0],X_temp.shape[1]*X_temp.shape[2]))\n","X_temp = np.mean(X_temp, axis=0)\n","y_temp = y[:imgs]\n","\n","print(X_hat.shape, X_temp.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,4))\n","sns.kdeplot(x=X_hat, label='Sampled data', linewidth=3)\n","sns.kdeplot(x=X_temp, label='Real data', linewidth=3)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imgs = 1000\n","fig, axes = plt.subplots(2, 5, figsize=(28,12), sharey=True, sharex=True)\n","fig.suptitle('Classes pixels distributions')\n","for i in range(10):\n","    X_hat, y_hat = generate_conditional_dataset(conditional_gan_generator, imgs, latent_dim, label=i)\n","    X_hat = np.reshape(X_hat, (X_hat.shape[0],X_hat.shape[1]*X_hat.shape[2]))*127.5 + 127+5\n","    X_hat = np.mean(X_hat, axis=0)\n","    X_temp = X[y==i][:imgs]*127.5 + 127+5\n","    X_temp = np.reshape(X_temp, (X_temp.shape[0],X_temp.shape[1]*X_temp.shape[2]))\n","    X_temp = np.mean(X_temp, axis=0)\n","    axes[i//5, i%5].set_title(f'Class {i}')\n","    sns.kdeplot(ax=axes[i//5, i%5], x=X_hat, label='Sampled data', linewidth=2)\n","    sns.kdeplot(ax=axes[i//5, i%5], x=X_temp, label='Real data', linewidth=2)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(num_classes):\n","    conditional_sample(conditional_gan_generator, 10, latent_dim, gray=True, fixed=False, label=i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Choose the number of intermediate images that would be generated in\n","# between the interpolation + 2 (start and last images).\n","num_interpolation = 500  \n","\n","# Sample noise for the interpolation.\n","interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n","interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n","interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n","\n","\n","def interpolate_class(first_number, second_number):\n","    # Convert the start and end labels to one-hot encoded vectors.\n","    first_label = tfk.utils.to_categorical([first_number], num_classes)\n","    second_label = tfk.utils.to_categorical([second_number], num_classes)\n","    first_label = tf.cast(first_label, tf.float32)\n","    second_label = tf.cast(second_label, tf.float32)\n","\n","    # Calculate the interpolation vector between the two labels.\n","    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n","    percent_second_label = tf.cast(percent_second_label, tf.float32)\n","    interpolation_labels = (first_label * (1 - percent_second_label) + second_label * percent_second_label)\n","\n","    # Combine the noise and the labels and run inference with the generator.\n","    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n","    fake = conditional_gan_generator.predict(noise_and_labels, verbose=0)\n","    return fake\n","\n","\n","start_class = 0  \n","end_class = 1  \n","\n","fake_images = interpolate_class(start_class, end_class)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fake_images = interpolate_class(start_class, end_class)*127.5 + 127.5\n","converted_images = fake_images.astype(np.uint8)\n","converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n","imageio.mimsave(\"animation01.gif\", converted_images, fps=60)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["MdD_8Vyswkwf","8v_dp0jkICtG","NcLWIZfBUd80","IrkPQZMVUp_K","mtSzHoNCVIQb","s70orp99V8G0","trMoDWu0VUWr","5hKARwDKelr1","oAvHsXOheqY9","TCaGhb5ttXGc","1WkDt6EWbGaU","G5NshBApbK50","gP0T-xVEeLGY","0kV-qxsiefOm","TpXLba4kehcs","GuWlVPNmup0D","YEryAxoREzRz","m7nfE8S_usaE","6KdIBFKW7ZdX"],"gpuType":"T4","provenance":[{"file_id":"12ODGsMkMPxFykDXp0w1dWj_F1FDU65sh","timestamp":1633524062268}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
